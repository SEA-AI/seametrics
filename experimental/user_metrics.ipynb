{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        1: {'gt_count': 301, 'tp_count': 0},\n",
      "        2: {'gt_count': 301, 'tp_count': 215},\n",
      "    },\n",
      "    {\n",
      "        1: {'gt_count': 300, 'tp_count': 4},\n",
      "        2: {'gt_count': 300, 'tp_count': 237},\n",
      "    },\n",
      "    {\n",
      "        1: {'gt_count': 300, 'tp_count': 15},\n",
      "        2: {'gt_count': 300, 'tp_count': 250},\n",
      "        3: {'gt_count': 280, 'tp_count': 206},\n",
      "    },\n",
      "    {\n",
      "        3: {'gt_count': 201, 'tp_count': 201},\n",
      "        1: {'gt_count': 201, 'tp_count': 56},\n",
      "        2: {'gt_count': 201, 'tp_count': 180},\n",
      "    },\n",
      "]\n",
      "[\n",
      "    {1: {'pred_count': 229, 'matched': 215}},\n",
      "    {\n",
      "        1: {'pred_count': 292, 'matched': 237},\n",
      "        23: {'pred_count': 4, 'matched': 4},\n",
      "    },\n",
      "    {\n",
      "        1: {'pred_count': 300, 'matched': 250},\n",
      "        31: {'pred_count': 207, 'matched': 206},\n",
      "        23: {'pred_count': 15, 'matched': 15},\n",
      "    },\n",
      "    {\n",
      "        31: {'pred_count': 201, 'matched': 201},\n",
      "        1: {'pred_count': 201, 'matched': 180},\n",
      "        44: {'pred_count': 56, 'matched': 56},\n",
      "    },\n",
      "]\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "config_fpath = Path.home() / \".fiftyone\" / \"config.global_mongodb.json\"\n",
    "os.environ[\"FIFTYONE_CONFIG_PATH\"] = str(config_fpath)\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "import fiftyone as fo\n",
    "from fiftyone.core.utils import pprint\n",
    "from fiftyone.utils.iou import compute_ious\n",
    "\n",
    "metrics_description = \"\"\"\n",
    "### Detection Consistency (for \"% Ground Truth Seen\")\n",
    "- **Definition**: This term refers to the system's ability to reliably detect and track objects of interest within the monitored environment. It encapsulates how well the system performs in identifying objects across different conditions and time windows.\n",
    "- **Why It Matters**: It directly speaks to the system's effectiveness in covering the area it monitors, ensuring that fewer objects go unnoticed. Higher Detection Consistency means users can trust the system to catch more of what's happening, reducing the risk of missing critical events.\n",
    "\n",
    "### Precision Alerting (for \"% Matched Predictions\")\n",
    "- **Definition**: This focuses on the accuracy and relevance of the alerts generated by the system. It reflects the system's ability to distinguish between true objects of interest and false alarms.\n",
    "- **Why It Matters**: By optimizing for precision alerting, the system minimizes unnecessary notifications, focusing users' attention on what truly matters. This is especially important in high-stakes environments where each alert could require significant resources to address.\n",
    "\"\"\"\n",
    "\n",
    "def load_sample():\n",
    "    \"\"\"\n",
    "    Dummy function to mimic dataset loading, replace with actual dataset loading logic.\n",
    "    \"\"\"\n",
    "    fpath = \"/mnt/FiftyOneSentry/Database/Sentry_Videos/Videos_8Bit/Sentry_2023_02_Portugal/Sentry_recordings_2023_01_24_20_47_46/Sentry_TwFoV_record_2023_01_24_20_47_46.mp4\"\n",
    "    dataset = fo.load_dataset(\"SENTRY_VIDEOS_DATASET_QA\")\n",
    "    return dataset[fpath]\n",
    "\n",
    "\n",
    "def find_range_index(ranges: List[tuple], n: int) -> int:\n",
    "    \"\"\"\n",
    "    Finds the index of the range that contains the given number.\n",
    "\n",
    "    Args:\n",
    "        ranges: A list of tuples representing the ranges.\n",
    "        n: The number to find the range index for.\n",
    "\n",
    "    Returns:\n",
    "        The index of the range that contains the number, or -1 if no range contains the\n",
    "        number.\n",
    "    \"\"\"\n",
    "    return next((i for i, (start, end) in enumerate(ranges) if start <= n <= end), -1)\n",
    "\n",
    "\n",
    "def update_stats(\n",
    "    frame: fo.Frame, gt_field: str, pred_field: str, gt_stats: dict, pred_stats: dict\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Updates the statistics for ground truth and predictions based on the given frame.\n",
    "\n",
    "    Args:\n",
    "        frame: The frame containing the ground truth and predictions.\n",
    "        pred_field: The field name for the predictions.\n",
    "        gt_stats: A dictionary to store the ground truth statistics.\n",
    "        pred_stats: A dictionary to store the prediction statistics.\n",
    "    \"\"\"\n",
    "    preds: List[fo.Detection] = frame[f\"{pred_field}.detections\"]\n",
    "    gts: List[fo.Detection] = frame[f\"{gt_field}.detections\"]\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred.index not in pred_stats:\n",
    "            pred_stats[pred.index] = {\"pred_count\": 1, \"matched\": 0}\n",
    "        else:\n",
    "            pred_stats[pred.index][\"pred_count\"] += 1\n",
    "\n",
    "    for gt in gts:\n",
    "        if gt.index not in gt_stats:\n",
    "            gt_stats[gt.index] = {\"gt_count\": 1, \"tp_count\": 0}\n",
    "        else:\n",
    "            gt_stats[gt.index][\"gt_count\"] += 1\n",
    "\n",
    "        ious = compute_ious([gt], preds)\n",
    "        if np.any(ious > 0):\n",
    "            gt_stats[gt.index][\"tp_count\"] += 1\n",
    "            matched_idx = np.where(ious > 0)[1]\n",
    "            for idx in matched_idx:\n",
    "                pred_stats[preds[idx].index][\"matched\"] += 1\n",
    "\n",
    "\n",
    "def calculate_chunk_metrics(\n",
    "    time_ranges: List[tuple], frames: List[fo.Frame], gt_field: str, pred_field: str\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Calculates the statistics for each chunk of frames.\n",
    "\n",
    "    Args:\n",
    "        time_ranges: A list of tuples representing the time ranges for each chunk.\n",
    "        frames: A list of frames.\n",
    "        pred_field: The field name for the predictions.\n",
    "\n",
    "    Returns:\n",
    "        Two lists of dictionaries representing the ground truth and prediction\n",
    "        statistics for each chunk.\n",
    "    \"\"\"\n",
    "    gt_stats_chunks = [{} for _ in range(len(time_ranges))]\n",
    "    pred_stats_chunks = [{} for _ in range(len(time_ranges))]\n",
    "\n",
    "    for n, frame in frames.items():\n",
    "        i = find_range_index(time_ranges, n)\n",
    "        if i == -1:\n",
    "            continue\n",
    "        try:\n",
    "            update_stats(\n",
    "                frame, gt_field, pred_field, gt_stats_chunks[i], pred_stats_chunks[i]\n",
    "            )\n",
    "        except TypeError:\n",
    "            pass  # dirty fix for the error\n",
    "\n",
    "    return gt_stats_chunks, pred_stats_chunks\n",
    "\n",
    "\n",
    "def calculate_final_metrics(\n",
    "    gt_stats_chunks: List[dict],\n",
    "    pred_stats_chunks: List[dict],\n",
    "    percentage_seen: float,\n",
    "    percentage_matched: float,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Calculates the final metrics based on the ground truth and prediction statistics.\n",
    "\n",
    "    Args:\n",
    "        gt_stats_chunks (list):\n",
    "            A list of dictionaries representing the ground truth statistics for each\n",
    "            chunk.\n",
    "        pred_stats_chunks (list):\n",
    "            A list of dictionaries representing the prediction statistics for each\n",
    "            chunk.\n",
    "        percentage_seen (float):\n",
    "            The minimum percentage of ground truth seen to consider it as a true\n",
    "            positive.\n",
    "        percentage_matched (float):\n",
    "            The minimum percentage of matched predictions to consider it as a true\n",
    "            positive.\n",
    "\n",
    "    Returns:\n",
    "        The Detection Consistency and precision alerting metrics.\n",
    "    \"\"\"\n",
    "    tps = []\n",
    "    fps = []\n",
    "    for gt_chunk, pred_chunk in zip(gt_stats_chunks, pred_stats_chunks):\n",
    "\n",
    "        for gt_stats in gt_chunk.values():\n",
    "            gt_stats[\"percentage_seen\"] = gt_stats[\"tp_count\"] / gt_stats[\"gt_count\"]\n",
    "            gt_stats[\"true_positive\"] = gt_stats[\"percentage_seen\"] >= percentage_seen\n",
    "            tps.append(gt_stats[\"true_positive\"])\n",
    "\n",
    "        for pred_stats in pred_chunk.values():\n",
    "            pred_stats[\"percentage_matched\"] = (\n",
    "                pred_stats[\"matched\"] / pred_stats[\"pred_count\"]\n",
    "            )\n",
    "            pred_stats[\"true_positive\"] = (\n",
    "                pred_stats[\"percentage_matched\"] >= percentage_matched\n",
    "            )\n",
    "            fps.append(pred_stats[\"true_positive\"])\n",
    "\n",
    "    detection_reliability = np.mean(tps)\n",
    "    precision_alerting = np.mean(fps)\n",
    "    return detection_reliability, precision_alerting\n",
    "\n",
    "\n",
    "def calculate_chunks(\n",
    "    gt_field: str,\n",
    "    pred_field: str,\n",
    "    time_window: float,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Calculates the Detection Consistency and precision alerting metrics.\n",
    "\n",
    "    Args:\n",
    "        sample_pkl_path (str): The path to the sample pickle file.\n",
    "        pred_field (str): The field name for the predictions.\n",
    "        time_window (float): The time window in seconds.\n",
    "        percentage_seen (float): The minimum percentage of ground truth seen to consider\n",
    "            it as a true positive.\n",
    "        percentage_unmatched (float): The maximum percentage of unmatched predictions to\n",
    "            consider it as a false positive.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The Detection Consistency and precision alerting metrics.\n",
    "    \"\"\"\n",
    "    sample = load_sample()\n",
    "    frames = sample.frames\n",
    "\n",
    "    frames_window = int(time_window * sample.metadata.frame_rate)\n",
    "    time_ranges = [\n",
    "        (i, min(i + frames_window, len(frames)))\n",
    "        for i in range(1, len(frames) + 1, frames_window)\n",
    "    ]\n",
    "\n",
    "    return calculate_chunk_metrics(time_ranges, frames, gt_field, pred_field)\n",
    "\n",
    "\n",
    "def gradio_interface(\n",
    "    _,  # video,\n",
    "    percentage_seen=0.1,\n",
    "    percentage_matched=0.9,\n",
    "):\n",
    "    detection_reliability, precision_alerting = calculate_final_metrics(\n",
    "        gt_stats_chunks, pred_stats_chunks, percentage_seen, percentage_matched\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"Detection Consistency\": detection_reliability,\n",
    "        \"Precision Alerting\": precision_alerting,\n",
    "    }\n",
    "    return metrics, metrics_description\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=[\n",
    "        gr.Video(\n",
    "            \"/Users/kevinserrano/Downloads/Sentry_TwFoV_record_2023_01_24_20_47_46.mp4\",\n",
    "            interactive=False,\n",
    "            label=\"sample\",\n",
    "            autoplay=True\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            minimum=0, maximum=1, step=0.01, value=0.1, label=\"% Ground Truth Seen\"\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            minimum=0,\n",
    "            maximum=1,\n",
    "            step=0.01,\n",
    "            value=0.1,\n",
    "            label=\"% Matched Predictions\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Label(label=\"User Metrics\"),\n",
    "        gr.Markdown(metrics_description),\n",
    "    ],\n",
    "    title=\"User Metrics Calculator\",\n",
    "    allow_flagging='never',\n",
    ")\n",
    "\n",
    "gt_stats_chunks, pred_stats_chunks = calculate_chunks(\n",
    "    \"ground_truth_det\",\n",
    "    \"volcanic-sweep-3_02_2023_N_LN1_ep288_TRACKER\",\n",
    "    10,\n",
    ")\n",
    "\n",
    "pprint(gt_stats_chunks)\n",
    "pprint(pred_stats_chunks)\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
