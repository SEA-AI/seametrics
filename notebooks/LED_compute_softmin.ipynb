{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import MaskFormerForInstanceSegmentation, MaskFormerImageProcessor\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn.functional as NNF\n",
    "from fiftyone import ViewField as F\n",
    "import fiftyone as fo\n",
    "from cleanlab.segmentation.rank import get_label_quality_scores, issues_from_scores \n",
    "from cleanlab.segmentation.summary import display_issues\n",
    "from cleanlab.segmentation.filter import find_label_issues \n",
    "import time\n",
    "from transformers import MaskFormerForInstanceSegmentation\n",
    "from PIL import Image\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATASET_NAME = \"TRAIN_PANOPTIC_DATASET\"\n",
    "MODEL_PATH =  \"/mnt/hdd/maryam/models/model_panoptik_27k_saved_100epochs/last_model\"\n",
    "MODEL_NAME = \"maskformer-27k-100epochs\"\n",
    "# CATEGORIES_JSON_PATH =os.path.join(TEST_DATASET_PATH, \"panoptic_seaai_categories.json\")\n",
    "CLASS_NAMES = ['AERIAL_ANIMAL', 'CONSTRUCTION', 'CONTAINER', 'FAR_AWAY_OBJECT', 'FLOTSAM', 'HUMAN_IN_WATER', 'LAND', 'MARITIME_ANIMAL', 'MOTORBOAT', 'OWN_BOAT', 'PILLAR_BUOY', 'SAILING_BOAT_WITH_CLOSED_SAILS', 'SAILING_BOAT_WITH_OPEN_SAILS', 'SHIP', 'SKY', 'SPHERICAL_BUOY', 'WATER', 'WATERCRAFT']\n",
    "TARGET_SIZE = (640, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADE_MEAN = np.array([123.675, 116.280, 103.530]) / 255\n",
    "ADE_STD = np.array([58.395, 57.120, 57.375]) / 255\n",
    "\n",
    "image_transform = A.Compose([\n",
    "    A.Resize(width=512, height=512),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(DATASET_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_view = dataset.match(F(\"filepath\").ends_with([\"17995902_r.jpg\", \"15616105_r.jpg\", \"23562072_r.jpg\"])) #change this to be smaller than the entire dataset if you want to do a quick test\n",
    "dataset_view = dataset.match(F(\"metadata.height\")==640) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274555, 250206)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(dataset_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskFormerForInstanceSegmentation.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "processor = MaskFormerImageProcessor.from_pretrained(MODEL_PATH, use_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AERIAL_ANIMAL',\n",
       " 'CONSTRUCTION',\n",
       " 'CONTAINER',\n",
       " 'FAR_AWAY_OBJECT',\n",
       " 'FLOTSAM',\n",
       " 'HUMAN_IN_WATER',\n",
       " 'LAND',\n",
       " 'MARITIME_ANIMAL',\n",
       " 'MOTORBOAT',\n",
       " 'OWN_BOAT',\n",
       " 'PILLAR_BUOY',\n",
       " 'SAILING_BOAT_WITH_CLOSED_SAILS',\n",
       " 'SAILING_BOAT_WITH_OPEN_SAILS',\n",
       " 'SHIP',\n",
       " 'SKY',\n",
       " 'SPHERICAL_BUOY',\n",
       " 'WATER',\n",
       " 'WATERCRAFT']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_labels =  model.config.id2label\n",
    "[v for k,v in model_labels.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mask_to_image_size(image_size, bbox, mask, index):\n",
    "    height, width = image_size\n",
    "    image_size_mask = np.zeros(image_size, dtype=np.uint8)\n",
    "    \n",
    "    # Unpack bounding box coordinates\n",
    "    left, top, bbox_width, bbox_height = bbox\n",
    "    # Calculate absolute coordinates\n",
    "    abs_top = int(top * height)\n",
    "    abs_left = int(left * width)\n",
    "    abs_bottom = min(abs_top + int(bbox_height * height), height)\n",
    "    abs_right = min(abs_left + int(bbox_width * width), width)\n",
    "    \n",
    "    # Place mask in image mask\n",
    "    image_size_mask[abs_top:abs_bottom, abs_left:abs_right] = mask * index\n",
    "\n",
    "    return image_size_mask\n",
    "\n",
    "def create_image_mask(annotations, image_size):\n",
    "    \"\"\"\n",
    "    Create an image mask from a list of mask annotations.\n",
    "    \n",
    "    Args:\n",
    "    - annotations: List of annotations, where each annotation is a dictionary with keys 'bounding_box', 'mask', and 'index'.\n",
    "    - image_size: Tuple (height, width) representing the size of the image mask to be created.\n",
    "    \n",
    "    Returns:\n",
    "    - image_mask: NumPy array representing the image mask with object indexes.\n",
    "    \"\"\"\n",
    "    height, width = image_size\n",
    "    image_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        bbox = annotation['bounding_box']\n",
    "        mask = annotation['mask']\n",
    "        index = label_to_id[annotation['label']]\n",
    "        \n",
    "        object_mask_full = transform_mask_to_image_size(image_size, bbox, mask, index)\n",
    "        image_mask[object_mask_full>0] = index\n",
    "\n",
    "    return image_mask\n",
    "\n",
    "def normalize_mask(mask, obj_id):\n",
    "    # Find pixels belonging to the current object\n",
    "    y_indices, x_indices = np.where(mask == obj_id)\n",
    "        \n",
    "    # Calculate the bounding box\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "\n",
    "    # Normalize the bounding box\n",
    "    top, left = y_min / mask.shape[0], x_min / mask.shape[1]\n",
    "    width, height = (x_max - x_min) / mask.shape[1], (y_max - y_min) / mask.shape[0]\n",
    "    normalized_bb = [left, top, width, height]\n",
    "\n",
    "    # Create a binary mask for the object\n",
    "    obj_mask = (mask[y_min:y_max+1, x_min:x_max+1] == obj_id).astype(np.uint8)\n",
    "\n",
    "    return normalized_bb, obj_mask\n",
    "\n",
    "\n",
    "def softmin_output_to_fo_format(mask):\n",
    "    objects = np.unique(mask)\n",
    "    objects = objects[objects != 0]  # Exclude background\n",
    "\n",
    "    fo_annotations = []\n",
    "    for obj_id in objects:\n",
    "\n",
    "        normalized_bb, obj_mask = normalize_mask(mask, obj_id)\n",
    "\n",
    "        annotation = fo.Detection(bounding_box=normalized_bb, mask=obj_mask, label='softmin_error')\n",
    "        fo_annotations.append(annotation)\n",
    "\n",
    "    return fo_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_169_Seq_22/9295954_l.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9174771e2c474efcafdcd52911685c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03a323e281e4dfbbcbb18498c0c193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ba498caf0443b0ac7b9b947a23ddec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:02<00:22,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_361_Seq_147/24595227_r.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe77c7fe4ca4a4a9a00d67dd1345a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9582cbfb34f4264ad5b20645164dfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1099615b56cc488e9af12ef50b085e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [00:03<00:12,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_289_Seq_9/23565444_r.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9177fa2637da474fb06679f4b0a4e14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d880cd1fc0b242bfa46c2afdb31e3aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcc3d96549f4ac59e3bd10e70e81cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:04<00:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_239_Seq_20/17954445_l.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd508d80a4b40cabd0aabe62ec74226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131edd72194e43cc93377f88b946b40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7968289166947eda742045752872e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:04<00:06,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_140_Seq_2/3585662_r.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dd67b434d94f70b2056ac7e68f62dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab194a3dcd04fb196a24915d864ba52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5bf4e1354b46139be511a64806f66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:04,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_242_Seq_5/18005802_r.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a951dc3191458089702dd62fb9a756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9848fe071a1149978205efb6bcf0b272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bfcac02bba4fc296cef51e18189bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:06<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_361_Seq_117/24572631_l.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a0c80fabed45e3ab614c44fd9a04a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c670fffa63443d4a9866ba1c039e0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3291f2e27c4cf6a351d80acb4ef210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:07<00:02,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_197_Seq_179/13079556_r.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7308f7a5490f41bda94446dec61f0544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaac180e734a413aa008d0aabdbf53ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fb3649b28d45aeb5670e5c4521053d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:01,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_361_Seq_129/24583037_l.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360c6410549d48f987aea445bb978231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5e131e68f2455da1094a33f2c479a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1222e676ffe44fbc9dc5584416500183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:08<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 512, 3)\n",
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_250_Seq_76/18188318_l.jpg\n",
      "len pred probs  1\n",
      "ground_truth_label shape (1, 640, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac4264fdf13432ca94837d6ffa16173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9f5bcd2d3d4212b2627012d4c5b814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d6b54138344cc4867d4b30b7714e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 10.305758714675903 for 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "field_to_save = \"softmin_errors\"\n",
    "model_labels =  model.config.id2label\n",
    "num_samples = 10\n",
    "dataset_view = dataset.match(F(\"metadata.height\")==640).take(num_samples)\n",
    "\n",
    "pred_probs_list = []\n",
    "ground_truth_labels_list = []\n",
    "\n",
    "time0 = time.time()\n",
    "for sample in tqdm(dataset_view):\n",
    "    image_filepath = sample.filepath\n",
    "    # image = Image.open(image_filepath).convert('RGB')\n",
    "    image = np.array(Image.open(image_filepath))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    print(image.shape)\n",
    "    print(image_filepath)\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "\n",
    "    pixel_values = image_transform(image=np.array(image))[\"image\"]\n",
    "    pixel_values = np.moveaxis(pixel_values, -1, 0)\n",
    "    pixel_values = torch.from_numpy(pixel_values).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values.to(DEVICE))\n",
    "\n",
    "\n",
    "    class_queries_logits = outputs.class_queries_logits  # [batch_size, num_queries, num_classes+1]\n",
    "    masks_queries_logits = outputs.masks_queries_logits  # [batch_size, num_queries, height, width]\n",
    "\n",
    "    # Compute probabilities and remove the null class `[..., :-1]`\n",
    "    masks_classes = class_queries_logits.softmax(dim=-1)[..., :-1]\n",
    "    masks_probs = masks_queries_logits.sigmoid()  # [batch_size, num_queries, height, width]\n",
    "\n",
    "    # Compute semantic segmentation probabilities of shape (batch_size, num_classes, height, width)\n",
    "    pred_probs = torch.einsum(\"bqc, bqhw -> bchw\", masks_classes, masks_probs)\n",
    "    print(\"len pred probs \", len(pred_probs))\n",
    "    target_sizes=[image.size[::-1]]\n",
    "    # target_sizes = [TARGET_SIZE]\n",
    "    for idx in range(len(pred_probs)):\n",
    "        resized_probs = NNF.interpolate(\n",
    "            pred_probs[idx].unsqueeze(dim=0), size=target_sizes[idx], mode='bilinear', align_corners=False\n",
    "        )\n",
    "    pred_probs_np = resized_probs.cpu().numpy()\n",
    "\n",
    "    # ground_truth_label = create_image_mask(sample['ground_truth_det.detections'], image.size)\n",
    "    image_size = (image.size[1], image.size[0])\n",
    "\n",
    "    ground_truth_label = np.expand_dims(create_image_mask(sample['ground_truth_det.detections'], image_size), axis=0)\n",
    "    \n",
    "    print(\"ground_truth_label shape\", ground_truth_label.shape)\n",
    "    pred_probs_list.append(np.squeeze(pred_probs_np))\n",
    "    ground_truth_labels_list.append(np.squeeze(ground_truth_label))\n",
    "\n",
    "    issues = find_label_issues(ground_truth_label, pred_probs_np, downsample = 4, n_jobs=None, batch_size=1)\n",
    "    image_scores, pixel_scores = get_label_quality_scores(labels=ground_truth_label, pred_probs=pred_probs_np)\n",
    "    issues_from_score = issues_from_scores(image_scores, pixel_scores, threshold=0.5)\n",
    "\n",
    "    issues_mask = np.squeeze(issues_from_score.astype(int))\n",
    "\n",
    "    fo_annotations = softmin_output_to_fo_format(issues_mask)\n",
    "\n",
    "    # Softmin_score ranges from 0 to 1, such that lower scores indicate images more likely to contain some mislabeled pixels.\n",
    "    sample['softmin_score'] = round(image_scores[0],4)\n",
    "    #save in the required field in fiftyone sample\n",
    "    sample[field_to_save] = fo.Detections(detections=fo_annotations)\n",
    "    sample.save()\n",
    "\n",
    "time1 = time.time()\n",
    "print(f\"It took {str(time1-time0)} for {num_samples}\")\n",
    "\n",
    "pred_probs_all_np = np.stack(pred_probs_list, axis=0)\n",
    "ground_truth_labels_all_np = np.stack(ground_truth_labels_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fiftyoneDB/Database/Image_Data/Thermal_Images_8Bit/Trip_46_Seq_7/1355061_l.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8eac62436e45edb30058d7651be0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2b84ecc7364cbb9f4123338bef10d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 20480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2030a392cd4403690381b0d078c9492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "field_to_save = \"softmin_errors\"\n",
    "\n",
    "sample = dataset_view.first()\n",
    "\n",
    "image_filepath = sample.filepath\n",
    "print(image_filepath)\n",
    "# image = Image.open(image_filepath).convert('RGB')\n",
    "image = np.array(Image.open(image_filepath))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = Image.fromarray(image)\n",
    "\n",
    "pixel_values = image_transform(image=np.array(image))[\"image\"]\n",
    "pixel_values = np.moveaxis(pixel_values, -1, 0)\n",
    "pixel_values = torch.from_numpy(pixel_values).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(pixel_values.to(DEVICE))\n",
    "\n",
    "\n",
    "class_queries_logits = outputs.class_queries_logits  # [batch_size, num_queries, num_classes+1]\n",
    "masks_queries_logits = outputs.masks_queries_logits  # [batch_size, num_queries, height, width]\n",
    "\n",
    "# Compute probabilities and remove the null class `[..., :-1]`\n",
    "masks_classes = class_queries_logits.softmax(dim=-1)[..., :-1]\n",
    "masks_probs = masks_queries_logits.sigmoid()  # [batch_size, num_queries, height, width]\n",
    "\n",
    "# Compute semantic segmentation probabilities of shape (batch_size, num_classes, height, width)\n",
    "pred_probs = torch.einsum(\"bqc, bqhw -> bchw\", masks_classes, masks_probs)\n",
    "target_sizes=[image.size[::-1]]\n",
    "for idx in range(len(pred_probs)):\n",
    "    resized_probs = NNF.interpolate(\n",
    "        pred_probs[idx].unsqueeze(dim=0), size=target_sizes[idx], mode='bilinear', align_corners=False\n",
    "    )\n",
    "pred_probs_np = resized_probs.cpu().numpy()\n",
    "\n",
    "# ground_truth_label = create_image_mask(sample['ground_truth_det.detections'], image.size)\n",
    "image_size = (image.size[1], image.size[0])\n",
    "\n",
    "ground_truth_label = np.expand_dims(create_image_mask(sample['ground_truth_det.detections'], image_size), axis=0)\n",
    "\n",
    "issues = find_label_issues(ground_truth_label, pred_probs_np, downsample = 4, n_jobs=None, batch_size=1)\n",
    "image_scores, pixel_scores = get_label_quality_scores(labels=ground_truth_label, pred_probs=pred_probs_np)\n",
    "issues_from_score = issues_from_scores(image_scores, pixel_scores, threshold=0.5)\n",
    "\n",
    "issues_mask = np.squeeze(issues_from_score.astype(int))\n",
    "\n",
    "fo_annotations = softmin_output_to_fo_format(issues_mask)\n",
    "\n",
    "# Softmin_score ranges from 0 to 1, such that lower scores indicate images more likely to contain some mislabeled pixels.\n",
    "sample['softmin_score'] = round(image_scores[0],4)\n",
    "#save in the required field in fiftyone sample\n",
    "sample[field_to_save] = fo.Detections(detections=fo_annotations)\n",
    "sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# issues = find_label_issues(ground_truth_labels_all_np, pred_probs_all_np, downsample = 4, n_jobs=None, batch_size=1)\n",
    "# image_scores, pixel_scores = get_label_quality_scores(labels=ground_truth_labels_all_np, pred_probs=pred_probs_all_np)\n",
    "# issues_from_score = issues_from_scores(image_scores, pixel_scores, threshold=0.5)\n",
    "\n",
    "display_issues(issues_from_score, labels=ground_truth_label, pred_probs=pred_probs_np, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de4138536a74a948bf7fe44df4a5435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for estimating thresholds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234c872e352d4c7783746cf34c7ada09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "number of examples processed for checking labels:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples whose labels have been evaluated: 204800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60185a1e1154789bb2773a2d6a2faa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images processed using softmin:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "issues = find_label_issues(ground_truth_labels_all_np, pred_probs_all_np, downsample = 4, n_jobs=None, batch_size=8)\n",
    "image_scores, pixel_scores = get_label_quality_scores(labels=ground_truth_labels_all_np, pred_probs=pred_probs_all_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
