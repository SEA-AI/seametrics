{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example of metrics for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detection import PrecisionRecallF1Support\n",
    "np.random.seed(42) # reproducibility\n",
    "\n",
    "def xywh_to_xyxy(bbox, img_width=None, img_height=None):\n",
    "    x, y, w, h = bbox\n",
    "    if img_height and img_width:\n",
    "        xyxy = [x * img_width, y * img_height, (x + w) * img_width, (y + h) * img_height]\n",
    "    else:\n",
    "        xyxy = [x, y, x + w, y + h]\n",
    "    return xyxy\n",
    "\n",
    "def random_box_generator(img_dims, max_h, max_w, n):\n",
    "    img_height, img_width = img_dims\n",
    "    boxes = []\n",
    "    for i in range(n):\n",
    "        x = np.random.randint(0, img_width)\n",
    "        y = np.random.randint(0, img_height)\n",
    "        w = np.random.randint(0, min(max_w, img_width - x))\n",
    "        h = np.random.randint(0, min(max_h, img_height - y))\n",
    "        boxes.append([x, y, w, h])\n",
    "    return boxes\n",
    "\n",
    "# create gt bboxes in xywh format\n",
    "gt_bboxes = np.array([\n",
    "    [180, 180, 300, 300],\n",
    "    [10, 15, 100, 100],\n",
    "])\n",
    "gt_labels = np.array([\"object\"] * len(gt_bboxes))\n",
    "\n",
    "# create pred bboxes in xywh format\n",
    "pred_bboxes = random_box_generator((500, 500), 100, 100, 10)\n",
    "pred_labels = np.array([\"object\"] * len(pred_bboxes))\n",
    "pred_scores = np.array([1.0] * len(pred_bboxes))\n",
    "\n",
    "# plot bboxes\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.imshow(np.ones((500, 500, 3)))\n",
    "for i, bbox in enumerate(gt_bboxes):\n",
    "    xy = bbox[:2]\n",
    "    w, h = bbox[2:]\n",
    "    ax.add_patch(plt.Rectangle(xy, w, h, fill=False, color=\"g\"))\n",
    "for i, bbox in enumerate(pred_bboxes):\n",
    "    xy = bbox[:2]\n",
    "    w, h = bbox[2:]\n",
    "    ax.add_patch(plt.Rectangle(xy, w, h, fill=False, color=\"b\"))\n",
    "# hide axis\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target=[{'boxes': tensor([[180, 180, 480, 480],\n",
      "        [ 10,  15, 110, 115]]), 'labels': tensor([0, 0])}, {'boxes': tensor([[180, 180, 480, 480],\n",
      "        [ 10,  15, 110, 115]]), 'labels': tensor([0, 0])}]\n",
      "preds=[{'boxes': tensor([[102, 435, 194, 449],\n",
      "        [106,  71, 166,  91],\n",
      "        [102, 121, 184, 207],\n",
      "        [330, 458, 417, 493],\n",
      "        [359, 151, 361, 172],\n",
      "        [308, 257, 395, 286],\n",
      "        [293, 385, 356, 444],\n",
      "        [276, 160, 351, 217],\n",
      "        [ 21, 252, 109, 300],\n",
      "        [474,  58, 483, 149]]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)}, {'boxes': tensor([[102, 435, 194, 449],\n",
      "        [106,  71, 166,  91],\n",
      "        [102, 121, 184, 207],\n",
      "        [330, 458, 417, 493],\n",
      "        [359, 151, 361, 172],\n",
      "        [308, 257, 395, 286],\n",
      "        [293, 385, 356, 444],\n",
      "        [276, 160, 351, 217],\n",
      "        [ 21, 252, 109, 300],\n",
      "        [474,  58, 483, 149]]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)}]\n"
     ]
    }
   ],
   "source": [
    "from detection.utils import prepare_data_for_det_metrics\n",
    "\n",
    "target, preds = prepare_data_for_det_metrics(\n",
    "    [gt_bboxes, gt_bboxes], [gt_labels, gt_labels],\n",
    "    [pred_bboxes, pred_bboxes], [pred_labels, pred_labels], [pred_scores, pred_scores]\n",
    ")\n",
    "\n",
    "print(f\"{target=}\\n{preds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             METRIC     tp,     fp,     fn,    dup,    pr,    re,    f1,   supp,    fpi,  nImgs\n",
      "@[ IoU=0.00      | area=      all | maxDets=100 ] =      4,     16,      0,     10,  0.20,  1.00,  0.33,      4,      0,      2\n",
      "@[ IoU=0.00      | area=    small | maxDets=100 ] =     -1,     -1,     -1,     -1, -1.00, -1.00, -1.00,      0,      0,      2\n",
      "@[ IoU=0.00      | area=   medium | maxDets=100 ] =      0,      2,      0,      0,  0.00,  0.00,  0.00,      0,      2,      2\n",
      "@[ IoU=0.00      | area=    large | maxDets=100 ] =      4,     14,      0,     10,  0.22,  1.00,  0.36,      4,      0,      2\n"
     ]
    }
   ],
   "source": [
    "area_ranges_tuples = [\n",
    "    (\"all\", [0, 1e5 ** 2]),\n",
    "    (\"small\", [0 ** 2, 6 ** 2]),\n",
    "    (\"medium\", [6 ** 2, 12 ** 2]),  \n",
    "    (\"large\", [12 ** 2, 1e5 ** 2])\n",
    "]\n",
    "area_ranges = [v for k, v in area_ranges_tuples]\n",
    "area_ranges_labels = [k for k, v in area_ranges_tuples]\n",
    "\n",
    "metric = PrecisionRecallF1Support(\n",
    "    iou_thresholds=[1e-10],\n",
    "    area_ranges=area_ranges,\n",
    "    area_ranges_labels=area_ranges_labels,\n",
    ")\n",
    "metric.update(preds, target)\n",
    "results = metric.compute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.keys()=dict_keys(['params', 'eval', 'metrics'])\n",
      "('all', {'range': [0, 10000000000.0], 'iouThr': '0.00', 'maxDets': 100, 'tp': 4, 'fp': 16, 'fn': 0, 'duplicates': 10, 'precision': 0.2, 'recall': 1.0, 'f1': 0.33333333333333337, 'support': 4, 'fpi': 0, 'nImgs': 2})\n",
      "('small', {'range': [0, 36], 'iouThr': '0.00', 'maxDets': 100, 'tp': -1, 'fp': -1, 'fn': -1, 'duplicates': -1, 'precision': -1, 'recall': -1, 'f1': -1, 'support': 0, 'fpi': 0, 'nImgs': 2})\n",
      "('medium', {'range': [36, 144], 'iouThr': '0.00', 'maxDets': 100, 'tp': 0, 'fp': 2, 'fn': 0, 'duplicates': 0, 'precision': 0.0, 'recall': 0, 'f1': 0, 'support': 0, 'fpi': 2, 'nImgs': 2})\n",
      "('large', {'range': [144, 10000000000.0], 'iouThr': '0.00', 'maxDets': 100, 'tp': 4, 'fp': 14, 'fn': 0, 'duplicates': 10, 'precision': 0.2222222222222222, 'recall': 1.0, 'f1': 0.3636363636363636, 'support': 4, 'fpi': 0, 'nImgs': 2})\n"
     ]
    }
   ],
   "source": [
    "print(f\"{results.keys()=}\")\n",
    "for item in results['metrics'].items():\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage with FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RGB_train_2023-03-28',\n",
       " 'SAILING_28_06_2023_IR',\n",
       " 'SAILING_DATASET',\n",
       " 'SAILING_DATASET_QA',\n",
       " 'SENTRY_VIDEOS_DATASET_QA',\n",
       " 'TRAIN_THERMAL_DATASET_2023_06']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# connect to global DB instead of local one (adjust path accordingly)\n",
    "#os.environ[\"FIFTYONE_CONFIG_PATH\"] = os.path.expanduser('~') + \"/.fiftyone/config.global_mongodb.json\"\n",
    "\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(\"SENTRY_VIDEOS_DATASET_QA\")\n",
    "\n",
    "# modify at will\n",
    "det_gt_field = \"ground_truth_det\"\n",
    "\n",
    "models = [\n",
    "    dict(name=\"03_10_2022_N_LN1_ep48_FT\", conf_thr=0),\n",
    "    dict(name=\"volcanic-sweep-3_02_2023_N_LN1_ep288\", conf_thr=0),\n",
    "    dict(name=\"yolov5n_T16-8_D2306-v0_9C\", conf_thr=0.18),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection import PrecisionRecallF1Support\n",
    "from detection.utils import compute_metrics\n",
    "\n",
    "# define metric params\n",
    "area_ranges_tuples = [\n",
    "    (\"all\", [0, 1e5 ** 2]),\n",
    "    # ignore anything smaller than 1.53x1.53 in wFoV (6x6 in nFoV + unwated noise)\n",
    "    (\"valid_n\", [1.53 ** 2 + 1e-5, 1e5 ** 2]),\n",
    "    # ignore anything smaller than 6x6 in wFoV (we loose 6x6 --> 18x18 in nFoV)\n",
    "    (\"valid_w\", [6 ** 2 + 1e-5, 1e5 ** 2]),\n",
    "    (\"tiny\", [0, 1.53 ** 2]),\n",
    "    (\"small\", [1.53 ** 2, 6 ** 2]),\n",
    "    (\"medium\", [6 ** 2, 12 ** 2]),\n",
    "    (\"large\", [12 ** 2, 1e5 ** 2])\n",
    "]\n",
    "area_ranges = [v for k, v in area_ranges_tuples]\n",
    "area_ranges_labels = [k for k, v in area_ranges_tuples]\n",
    "\n",
    "metric_params = dict(\n",
    "    iou_thresholds=[1e-10],\n",
    "    area_ranges=area_ranges,\n",
    "    area_ranges_labels=area_ranges_labels,\n",
    "    class_agnostic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 03_10_2022_N_LN1_ep48_FT #####\n",
      "Collecting bboxes, labels and scores...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to metric format...\n",
      "Computing metrics...\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"##### {model['name']} #####\")\n",
    "    sentry_cnn_wFoV_results = compute_metrics(\n",
    "        view=(\n",
    "            dataset\n",
    "            .select_group_slices([\"thermal_wide\", \"thermal_narrow\"])\n",
    "            .filter_labels(f\"frames.{model['name']}\", F(\"confidence\") >= model['conf_thr'], only_matches=False)\n",
    "        ),\n",
    "        gt_field=det_gt_field,\n",
    "        pred_field=model['name'],\n",
    "        metric_fn=PrecisionRecallF1Support,\n",
    "        metric_kwargs=metric_params\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
